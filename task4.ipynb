{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08dac561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Regular Expressions - text pattern matching and cleaning text\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score,roc_curve \n",
    "import torch\n",
    "#transformers\n",
    "#prepares tweet-like text for models trained on Twitter data\n",
    "#BertweetTokenizer: prepares tweet-like text for models trained on Twitter data.\n",
    "#RobertaForSequenceClassification: pre-trained RoBERTa model for classification tasks.\n",
    "#Trainer & TrainingArguments: handle model training, evaluation, and optimization.\n",
    "from transformers import BertweetTokenizer,RobertaForSequenceClassification,Trainer,TrainingArguments\n",
    "#DataCollatorWithPadding: automatically pads variable-length text batches.\n",
    "#EarlyStoppingCallback: stops training early if validation loss doesn’t improve.\n",
    "from transformers import DataCollatorWithPadding,EarlyStoppingCallback\n",
    "#From Hugging Face Datasets, used to easily create and manage datasets.\n",
    "#Can convert pandas DataFrames into a dataset for use with transformers.\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdb799ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   1000 non-null   object\n",
      " 1   text    1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "df = pd.read_csv(\"Datasets/hydrogen_small.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02274b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>behind the wheel of a hydrogen powered car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>mls measurements of stratospheric hydrogen cya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>ana gonzalez hernandez shares an overview of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>toyota is giving away its first hydrogen car i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>agility develops storage systems for hydrogen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>a solarpower europe report sees europe achievi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>alstom engiegroup sign a partnership to supply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>colombia signs a hydrogen mou with the port of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>mr wizard s mini hydrogen bomb via youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Relevant</td>\n",
       "      <td>hand downs the best explanation i’ve heard abo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          label                                               text\n",
       "0      Relevant         behind the wheel of a hydrogen powered car\n",
       "1    Irrelevant  mls measurements of stratospheric hydrogen cya...\n",
       "2      Relevant  ana gonzalez hernandez shares an overview of h...\n",
       "3      Relevant  toyota is giving away its first hydrogen car i...\n",
       "4      Relevant  agility develops storage systems for hydrogen ...\n",
       "..          ...                                                ...\n",
       "995    Relevant  a solarpower europe report sees europe achievi...\n",
       "996    Relevant  alstom engiegroup sign a partnership to supply...\n",
       "997    Relevant  colombia signs a hydrogen mou with the port of...\n",
       "998  Irrelevant         mr wizard s mini hydrogen bomb via youtube\n",
       "999    Relevant  hand downs the best explanation i’ve heard abo...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4459f4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Relevant', 'Irrelevant'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a label indicating whether it is relevant\n",
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb02637b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'behind the wheel of a hydrogen powered car'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine the messages in the dataset to determine whether any cleaning or pre-processing is necessary\n",
    "df[\"text\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72a8a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_message(text):\n",
    "    #remove URLs from the message.\n",
    "    #re.sub(pattern, replacement, text)\n",
    "    #It returns a new string with the replacements made.\n",
    "    #pattern: the regular expression to search for (what you want to remove or replace).\n",
    "    #replacement: the string to replace the found pattern with.\n",
    "\n",
    "    #text: the original text to process.\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    #remove tags from the message\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "    #remove non-ASCII characters from the text\n",
    "    #like: emojis\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
    "\n",
    "    #replace any sequences of consecutive whitespace with a single space character.\n",
    "    #This includes newlines and spaces.\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    #remove whitespace from the start and end of the string\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34c12995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply it yo the messages in the dataset\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(clean_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6d8fc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             behind the wheel of a hydrogen powered car\n",
       "1      mls measurements of stratospheric hydrogen cya...\n",
       "2      ana gonzalez hernandez shares an overview of h...\n",
       "3      toyota is giving away its first hydrogen car i...\n",
       "4      agility develops storage systems for hydrogen ...\n",
       "                             ...                        \n",
       "995    a solarpower europe report sees europe achievi...\n",
       "996    alstom engiegroup sign a partnership to supply...\n",
       "997    colombia signs a hydrogen mou with the port of...\n",
       "998           mr wizard s mini hydrogen bomb via youtube\n",
       "999    hand downs the best explanation ive heard abou...\n",
       "Name: text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examing the message from above to confirm that the tag and URL have been removed\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9842c7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>behind the wheel of a hydrogen powered car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>mls measurements of stratospheric hydrogen cya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ana gonzalez hernandez shares an overview of h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>toyota is giving away its first hydrogen car i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>agility develops storage systems for hydrogen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "      <td>a solarpower europe report sees europe achievi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>alstom engiegroup sign a partnership to supply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>colombia signs a hydrogen mou with the port of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>mr wizard s mini hydrogen bomb via youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "      <td>hand downs the best explanation ive heard abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0        1         behind the wheel of a hydrogen powered car\n",
       "1        0  mls measurements of stratospheric hydrogen cya...\n",
       "2        1  ana gonzalez hernandez shares an overview of h...\n",
       "3        1  toyota is giving away its first hydrogen car i...\n",
       "4        1  agility develops storage systems for hydrogen ...\n",
       "..     ...                                                ...\n",
       "995      1  a solarpower europe report sees europe achievi...\n",
       "996      1  alstom engiegroup sign a partnership to supply...\n",
       "997      1  colombia signs a hydrogen mou with the port of...\n",
       "998      0         mr wizard s mini hydrogen bomb via youtube\n",
       "999      1  hand downs the best explanation ive heard abou...\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre-processing\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# create encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# learn the mapping\n",
    "le.fit(df[\"label\"])\n",
    "\n",
    "# transform the original column into numbers\n",
    "df[\"label\"] = le.transform(df[\"label\"])\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54349449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    547\n",
       "0    453\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()\n",
    "#Dataset is much smaller than that in the practical, no need to undersample then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6e2463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split these samples into a training/testing set that we will feed into the model.\n",
    "\n",
    "X = df[\"text\"].values\n",
    "y = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0b5636a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 700\n",
      "Testing set size: 300\n"
     ]
    }
   ],
   "source": [
    "random_state = 42\n",
    "\n",
    "test_set_size = 0.3 # 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set_size, stratify=y, random_state=random_state)\n",
    "print(\"Training set size:\", len(X_train))\n",
    "print(\"Testing set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24bab5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing data\n",
    "\n",
    "train_df = pd.DataFrame({\"text\":X_train, \"label\": y_train})\n",
    "test_df = pd.DataFrame({\"text\": X_test, \"label\":y_test})\n",
    "\n",
    "#converting DataFrames into Hugging Face datasets\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da26d045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    }
   ],
   "source": [
    "#download the embedding model\n",
    "\n",
    "model_name = \"vinai/bertweet-base\"\n",
    "tokenizer = BertweetTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf95019c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc74380fb58448ab6b34b842bfdbe4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/700 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a420aba0d74c5ea744b0861fbf361b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compute the tokens for each of the messages in our dataset\n",
    "\n",
    "def tokenize(batch):\n",
    "#batch['text'] takes the \"text\" column from the dataset\n",
    "#tokenizer(...) applies the Hugging Face tokenizer\n",
    "#truncation=True cuts off text longer than the model’s max length.\n",
    "#padding=True pads shorter texts so that all sequences in a batch have the same length.\n",
    "    return tokenizer(batch['text'],truncation=True,padding=True)\n",
    "\n",
    "train_ds = train_ds.map(tokenize,batched=True)\n",
    "test_ds = test_ds.map(tokenize,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66600768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 700\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f30cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Loading the Model\n",
    "# With the data ready to train the model we are using for transfer learning\n",
    "# need to download and load the base model.\n",
    "\n",
    "#in case there is a model assigned to this variable name\n",
    "\n",
    "try:\n",
    "    del model\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "#Download/load the base model. We use the \"vinai/bertweet-base\" model here.\n",
    "#set the number of labels to 2\n",
    "#set the problem type to single label classification\n",
    "#loads a RoBERTa model that’s already trained on language data (from Hugging Face)\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    #sets how many output classes the model should predict\n",
    "    num_labels=df[\"label\"].nunique(),\n",
    "    problem_type=\"single_label_classification\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e812876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the Model\n",
    "#define the metrics to compute after each epoch\n",
    "#define a metrics computing function compatible with the `transformers` library\n",
    "\n",
    "#This function tells the Hugging Face Trainer how to evaluate model after each epoch.\n",
    "\n",
    "# pred is an object the Trainer provides.\n",
    "# It contains:\n",
    "# pred.predictions: the raw model outputs (logits) — basically unnormalized scores for each class.\n",
    "# pred.label_ids: the true labels from dataset.\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    #convert model outputs to predicted classes\n",
    "    preds = pred.predictions.argmax(-1) #argmax(-1) picks the index of the highest value (largest logit) along the last axis.\n",
    "    acc = accuracy_score(labels,preds)\n",
    "    prec,recall,f1,_ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\", pos_label=1\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": recall,\n",
    "        \"f1\":f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0b2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up hyperparameters for the training process\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
